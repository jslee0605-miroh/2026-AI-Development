{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Screening with LLMs: Building Modular AI Systems\n",
    "\n",
    "**Goal**: Demonstrate building AI systems with well-defined inputs/outputs and vertical slices\n",
    "\n",
    "## Key Concepts\n",
    "1. **Modular Design**: Break complex tasks into functions with clear inputs/outputs\n",
    "2. **Vertical Slices**: Build end-to-end functionality for one case first\n",
    "3. **Horizontal Expansion**: Add features after vertical slice works\n",
    "\n",
    "## System Overview\n",
    "```\n",
    "Resume PDF/CSV → Extract Skills → Match to Job → Rank Candidates\n",
    "     (Input)         (Module 1)      (Module 2)      (Output)\n",
    "```\n",
    "\n",
    "## Setup\n",
    "This notebook requires:\n",
    "- `OPENROUTER_API_KEY`\n",
    "- `resumes_final.csv` in data directory\n",
    "- `job_req.md` in data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to Python path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "from resume_utils import (\n",
    "    load_resume_from_csv,\n",
    "    load_all_resumes,\n",
    "    load_job_req,\n",
    "    extract_skills,\n",
    "    match_to_job,\n",
    "    screen_resume_vertical_slice\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "OPENROUTER_API_KEY = \"\"  # Paste your key here\n",
    "MODEL = \"anthropic/claude-3.5-sonnet\"\n",
    "\n",
    "# File paths\n",
    "CSV_PATH = \"../data/resumes_final.csv\"\n",
    "JOB_REQ_PATH = \"../data/job_req.md\"\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY.strip() == \"\":\n",
    "    raise RuntimeError(\n",
    "        \"⚠️  Please set OPENROUTER_API_KEY above before running this notebook.\\n\"\n",
    "        \"Get your key from: https://openrouter.ai/keys\"\n",
    "    )\n",
    "\n",
    "print(\"✓ Imports loaded\")\n",
    "print(\"✓ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Data\n",
    "\n",
    "Before building any AI system, we need to understand our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the resume data\n",
    "resumes_df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(f\"Total resumes: {len(resumes_df)}\")\n",
    "print(f\"\\nCategories:\")\n",
    "print(resumes_df['Category'].value_counts())\n",
    "\n",
    "# Show sample resume IDs\n",
    "print(f\"\\nSample IT Resume IDs:\")\n",
    "it_resumes = resumes_df[resumes_df['Category'] == 'INFORMATION-TECHNOLOGY']['ID'].head(5).tolist()\n",
    "for rid in it_resumes:\n",
    "    print(f\"  {rid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display job requisition\n",
    "job_req = load_job_req(JOB_REQ_PATH)\n",
    "\n",
    "print(\"Job Requisition (first 500 characters):\")\n",
    "print(\"=\"*70)\n",
    "print(job_req[:500])\n",
    "print(\"...\")\n",
    "print(f\"\\nTotal length: {len(job_req)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building a Vertical Slice (Crawl Phase)\n",
    "\n",
    "**Goal**: Process ONE resume end-to-end to prove the concept works.\n",
    "\n",
    "### Module 1: Extract Skills\n",
    "**Input**: Resume text (string)  \n",
    "**Output**: Structured skills data (dict)\n",
    "\n",
    "This module has a single, clear responsibility: parse a resume and extract technical skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test skill extraction on ONE resume\n",
    "test_resume_id = it_resumes[0]  # Use first IT resume\n",
    "\n",
    "# Load the resume\n",
    "test_resume = load_resume_from_csv(CSV_PATH, test_resume_id)\n",
    "print(f\"Testing with Resume ID: {test_resume_id}\")\n",
    "print(f\"Category: {test_resume['Category']}\")\n",
    "print(f\"\\nResume text (first 500 chars):\")\n",
    "print(test_resume['Resume_str'][:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract skills using LLM\n",
    "print(\"Extracting skills...\")\n",
    "skills_result = extract_skills(\n",
    "    OPENROUTER_API_KEY,\n",
    "    test_resume['Resume_str'],\n",
    "    MODEL\n",
    ")\n",
    "\n",
    "if skills_result['error']:\n",
    "    print(f\"❌ Error: {skills_result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Skills extracted successfully\")\n",
    "    skills = skills_result['parsed_content']\n",
    "    \n",
    "    print(f\"\\nTokens used: {skills_result['usage'].get('total_tokens', 0)}\")\n",
    "    print(f\"\\nExtracted Skills:\")\n",
    "    print(json.dumps(skills, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 2: Match to Job Requirements\n",
    "**Input**: Skills dict + Job req text  \n",
    "**Output**: Match score and analysis (dict)\n",
    "\n",
    "This module takes the structured output from Module 1 and compares it to job requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match extracted skills to job requirements\n",
    "print(\"Matching to job requirements...\")\n",
    "match_result = match_to_job(\n",
    "    OPENROUTER_API_KEY,\n",
    "    skills,\n",
    "    job_req,\n",
    "    MODEL\n",
    ")\n",
    "\n",
    "if match_result['error']:\n",
    "    print(f\"❌ Error: {match_result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Matching completed successfully\")\n",
    "    match_data = match_result['parsed_content']\n",
    "    \n",
    "    print(f\"\\nTokens used: {match_result['usage'].get('total_tokens', 0)}\")\n",
    "    print(f\"\\nMatch Results:\")\n",
    "    print(json.dumps(match_data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Vertical Slice: End-to-End Pipeline\n",
    "\n",
    "Now that we've tested each module independently, let's combine them into a single pipeline.\n",
    "\n",
    "This is our **vertical slice**: one resume through the entire system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete pipeline on one resume\n",
    "print(f\"Running complete pipeline on resume {test_resume_id}...\\n\")\n",
    "\n",
    "result = screen_resume_vertical_slice(\n",
    "    OPENROUTER_API_KEY,\n",
    "    test_resume_id,\n",
    "    CSV_PATH,\n",
    "    JOB_REQ_PATH,\n",
    "    MODEL\n",
    ")\n",
    "\n",
    "if 'error' in result:\n",
    "    print(f\"❌ Error: {result['error']}\")\n",
    "else:\n",
    "    print(\"✓ Pipeline completed successfully\\n\")\n",
    "    print(f\"Resume ID: {result['resume_id']}\")\n",
    "    print(f\"Category: {result['category']}\")\n",
    "    print(f\"Total tokens: {result['total_tokens']}\")\n",
    "    print(f\"\\nFit Score: {result['match']['fit_score']}/100\")\n",
    "    print(f\"Recommendation: {result['match']['recommendation']}\")\n",
    "    print(f\"\\nReasoning: {result['match']['reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Horizontal Expansion (Walk Phase)\n",
    "\n",
    "**Goal**: Now that our vertical slice works, expand to process multiple resumes.\n",
    "\n",
    "### Batch Processing Multiple Resumes\n",
    "\n",
    "We can now reuse our tested pipeline to process multiple resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample of resumes to process\n",
    "# Mix of IT resumes and non-IT resumes\n",
    "it_sample = resumes_df[resumes_df['Category'] == 'INFORMATION-TECHNOLOGY']['ID'].head(3).tolist()\n",
    "non_it_sample = resumes_df[resumes_df['Category'] != 'INFORMATION-TECHNOLOGY']['ID'].head(2).tolist()\n",
    "\n",
    "sample_ids = it_sample + non_it_sample\n",
    "\n",
    "print(f\"Processing {len(sample_ids)} resumes...\")\n",
    "print(f\"IT resumes: {len(it_sample)}\")\n",
    "print(f\"Non-IT resumes: {len(non_it_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all sample resumes\n",
    "results = []\n",
    "total_tokens = 0\n",
    "\n",
    "for i, resume_id in enumerate(sample_ids, 1):\n",
    "    print(f\"\\n[{i}/{len(sample_ids)}] Processing {resume_id}...\")\n",
    "    \n",
    "    result = screen_resume_vertical_slice(\n",
    "        OPENROUTER_API_KEY,\n",
    "        resume_id,\n",
    "        CSV_PATH,\n",
    "        JOB_REQ_PATH,\n",
    "        MODEL\n",
    "    )\n",
    "    \n",
    "    if 'error' in result:\n",
    "        print(f\"  ❌ Error: {result['error']}\")\n",
    "        results.append({\n",
    "            'resume_id': resume_id,\n",
    "            'error': result['error']\n",
    "        })\n",
    "    else:\n",
    "        print(f\"  ✓ Score: {result['match']['fit_score']}/100 - {result['match']['recommendation']}\")\n",
    "        results.append(result)\n",
    "        total_tokens += result['total_tokens']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"Batch processing complete!\")\n",
    "print(f\"Total tokens used: {total_tokens:,}\")\n",
    "print(f\"Estimated cost: ${total_tokens * 3 / 1_000_000:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank and Compare Candidates\n",
    "\n",
    "Now we can analyze and rank all candidates based on their fit scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from results\n",
    "results_data = []\n",
    "for r in results:\n",
    "    if 'error' not in r:\n",
    "        results_data.append({\n",
    "            'Resume ID': r['resume_id'],\n",
    "            'Category': r['category'],\n",
    "            'Fit Score': r['match']['fit_score'],\n",
    "            'Recommendation': r['match']['recommendation'],\n",
    "            'Matching Skills Count': len(r['match']['matching_skills']),\n",
    "            'Missing Skills Count': len(r['match']['missing_skills']),\n",
    "            'Tokens': r['total_tokens']\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_data)\n",
    "results_df = results_df.sort_values('Fit Score', ascending=False)\n",
    "\n",
    "print(\"Candidate Rankings:\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results for top candidate\n",
    "if len(results) > 0 and 'error' not in results[0]:\n",
    "    top_result = results_df.iloc[0]\n",
    "    top_resume_id = top_result['Resume ID']\n",
    "    \n",
    "    # Find full result\n",
    "    top_full = next(r for r in results if r.get('resume_id') == top_resume_id)\n",
    "    \n",
    "    print(f\"\\nTop Candidate Details: {top_resume_id}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFit Score: {top_full['match']['fit_score']}/100\")\n",
    "    print(f\"Recommendation: {top_full['match']['recommendation']}\")\n",
    "    print(f\"\\nMatching Skills ({len(top_full['match']['matching_skills'])}):\")\n",
    "    for skill in top_full['match']['matching_skills'][:10]:  # Show first 10\n",
    "        print(f\"  ✓ {skill}\")\n",
    "    if len(top_full['match']['matching_skills']) > 10:\n",
    "        print(f\"  ... and {len(top_full['match']['matching_skills']) - 10} more\")\n",
    "    \n",
    "    print(f\"\\nMissing Skills ({len(top_full['match']['missing_skills'])}):\")\n",
    "    for skill in top_full['match']['missing_skills'][:5]:  # Show first 5\n",
    "        print(f\"  ✗ {skill}\")\n",
    "    \n",
    "    print(f\"\\nReasoning:\")\n",
    "    print(f\"  {top_full['match']['reasoning']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Analysis and Insights\n",
    "\n",
    "### What Did We Build?\n",
    "\n",
    "1. **Modular Design**: Each function has clear inputs/outputs\n",
    "   - `extract_skills(resume_text) -> skills_dict`\n",
    "   - `match_to_job(skills, job_req) -> match_dict`\n",
    "   - `screen_resume_vertical_slice(resume_id) -> full_result`\n",
    "\n",
    "2. **Vertical Slice First**: We tested one resume end-to-end before expanding\n",
    "   - Verified each module works independently\n",
    "   - Combined into complete pipeline\n",
    "   - Only then expanded to batch processing\n",
    "\n",
    "3. **Easy to Test and Debug**: Each piece can be tested independently\n",
    "   - If skill extraction fails, we know exactly where the problem is\n",
    "   - If matching is poor, we can improve just that module\n",
    "   - Clear boundaries make debugging straightforward\n",
    "\n",
    "### Next Steps (Run Phase)\n",
    "\n",
    "To make this production-ready, we would add:\n",
    "- Error handling and retry logic\n",
    "- Caching of job requirements and common skills\n",
    "- Cost tracking and budgeting\n",
    "- Human-in-the-loop review for borderline cases\n",
    "- Prompt optimization based on accuracy metrics\n",
    "- Parallel processing for large batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Identify Non-IT Resumes\n",
    "\n",
    "Our dataset includes 10 non-IT resumes mixed in with 120 IT resumes.\n",
    "\n",
    "**Challenge**: Did our system correctly identify the non-IT resumes with low scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which resumes are actually non-IT\n",
    "if len(results_df) > 0:\n",
    "    print(\"Non-IT Resumes in Our Sample:\")\n",
    "    print(\"=\"*70)\n",
    "    non_it_results = results_df[results_df['Category'] != 'INFORMATION-TECHNOLOGY']\n",
    "    if len(non_it_results) > 0:\n",
    "        print(non_it_results.to_string(index=False))\n",
    "        print(f\"\\nAverage fit score for non-IT: {non_it_results['Fit Score'].mean():.1f}\")\n",
    "    else:\n",
    "        print(\"No non-IT resumes in this sample\")\n",
    "    \n",
    "    print(f\"\\nIT Resumes in Our Sample:\")\n",
    "    print(\"=\"*70)\n",
    "    it_results = results_df[results_df['Category'] == 'INFORMATION-TECHNOLOGY']\n",
    "    if len(it_results) > 0:\n",
    "        print(it_results.to_string(index=False))\n",
    "        print(f\"\\nAverage fit score for IT: {it_results['Fit Score'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Break problems into pieces with clear interfaces**\n",
    "   - Each function does one thing well\n",
    "   - Easy to test, debug, and improve\n",
    "\n",
    "2. **Build vertical slices first**\n",
    "   - Prove end-to-end flow works with simplest case\n",
    "   - Identify integration issues early\n",
    "\n",
    "3. **Expand horizontally after vertical slice works**\n",
    "   - Add batch processing\n",
    "   - Add error handling and edge cases\n",
    "   - Don't optimize prematurely\n",
    "\n",
    "4. **AI systems especially benefit from this approach**\n",
    "   - LLM behavior is less predictable\n",
    "   - Modular design helps isolate issues\n",
    "   - Easy to swap models or prompts for specific steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
