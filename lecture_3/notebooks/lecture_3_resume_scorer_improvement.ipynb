{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3 — Improving the Resume Scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add current directory to Python path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from resume_utils import load_resumes, load_job_requirements, structured_llm_call\n",
    "\n",
    "random.seed(111)\n",
    "\n",
    "# Configuration\n",
    "OPENROUTER_API_KEY = \"\"  # Paste your key here\n",
    "\n",
    "if not OPENROUTER_API_KEY or OPENROUTER_API_KEY.strip() == \"\":\n",
    "    raise RuntimeError(\n",
    "        \"⚠️  Please set OPENROUTER_API_KEY above before running this notebook.\\n\"\n",
    "        \"Get your key from: https://openrouter.ai/keys\"\n",
    "    )\n",
    "\n",
    "print(\"✓ Imports loaded\")\n",
    "print(\"✓ API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Sample Resumes\n",
    "\n",
    "Load resume data and randomly sample a subset for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = load_resumes('../data/resumes_final.csv')\n",
    "job_req = load_job_requirements('../data/job_req_senior.md')\n",
    "\n",
    "print(f\"Loaded {len(resumes)} resumes\")\n",
    "\n",
    "resume_list = list(resumes.values())\n",
    "resume_samples = random.sample(resume_list, 3)\n",
    "print(f\"Selected {len(resume_samples)} resumes for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Monolithic Approach\n",
    "\n",
    "Start with a single prompt that does everything:\n",
    "- Reads the resume\n",
    "- Compares it to job requirements\n",
    "- Outputs a 0-100 score\n",
    "\n",
    "This is our baseline to compare against improved approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: Single prompt that does everything\n",
    "baseline_prompt = \"\"\"\n",
    "Score this resume against the job requirements on a 0-100 scale.\n",
    "\n",
    "Consider:\n",
    "- Years of experience required (5-10 years)\n",
    "- Technical skills match\n",
    "- Education level\n",
    "- Overall fit\n",
    "\n",
    "Provide a final score.\n",
    "\"\"\"\n",
    "\n",
    "baseline_schema = {\n",
    "    \"score\": \"number (0-100)\",\n",
    "    \"reasoning\": \"string explaining the score\"\n",
    "}\n",
    "\n",
    "# Collect results for all resumes\n",
    "results = []\n",
    "\n",
    "for idx, resume in enumerate(resume_samples):\n",
    "    print(f\"{idx+1} of {len(resume_samples)}\")\n",
    "    baseline_result = structured_llm_call(\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "        prompt=baseline_prompt,\n",
    "        context_data={\n",
    "            \"resume\": resume['Resume_str'],\n",
    "            \"job_requirements\": job_req\n",
    "        },\n",
    "        output_schema=baseline_schema,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'resume_id': resume['ID'],\n",
    "        'score': baseline_result['result'].get('score', None),\n",
    "        'tokens': baseline_result['usage'].get('total_tokens', 0),        \n",
    "        'reasoning': baseline_result['result'].get('reasoning', ''),\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "monolith_scores_df = pd.DataFrame(results)\n",
    "\n",
    "print(3*'\\n')\n",
    "print(monolith_scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODO 1: Decompose - Extract Years of Experience\n",
    "\n",
    "**Goal**: Break down the monolithic approach by extracting specific features first.\n",
    "\n",
    "**Your Task**:\n",
    "1. Create a prompt that extracts ONLY years of experience\n",
    "2. Require evidence/citations from the resume\n",
    "3. Define an output schema for the extraction\n",
    "4. Use `structured_llm_call` to run it on all resume samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 1: Write your extraction prompt here\n",
    "# Hints:\n",
    "# - Focus ONLY on extracting years of experience\n",
    "# - Require citations/evidence from the resume\n",
    "# - Be specific about what counts as \"experience\"\n",
    "\n",
    "number_of_years_extraction_prompt = \"\"\"\n",
    "WRITE YOUR OWN PROMPT AND SEE IF IT WORKS.\n",
    "\"\"\"\n",
    "\n",
    "number_of_years_schema = {\n",
    "    \"years\": \"number (0-100)\",\n",
    "    \"reasoning\": \"string explaining how you calculated the years, with citations\"\n",
    "}\n",
    "\n",
    "results = []\n",
    "for idx, resume in enumerate(resume_samples):\n",
    "    print(f\"{idx+1} of {len(resume_samples)}\") \n",
    "    \n",
    "    year_result = structured_llm_call(\n",
    "        api_key=OPENROUTER_API_KEY,\n",
    "        prompt=number_of_years_extraction_prompt,\n",
    "        context_data={\n",
    "            \"resume\": resume['Resume_str'],\n",
    "            \"job_requirements\": job_req\n",
    "        },\n",
    "        output_schema=number_of_years_schema,\n",
    "        temperature=0.3\n",
    "        )\n",
    "\n",
    "    results.append({\n",
    "        'resume_id': resume['ID'],\n",
    "        'years_working': year_result['result'].get('years', None),\n",
    "        'tokens': year_result['usage'].get('total_tokens', 0),        \n",
    "        'reasoning': year_result['result'].get('reasoning', ''),\n",
    "    })\n",
    "\n",
    "\n",
    "# Create DataFrame from results\n",
    "work_experience_scores = pd.DataFrame(results)\n",
    "\n",
    "print(3*'\\n')\n",
    "print(work_experience_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODO 2: Extract and Score Relevant Technologies\n",
    "\n",
    "**Goal**: Extract technology skills from resumes and score them against job requirements.\n",
    "\n",
    "**Your Task**:\n",
    "1. Copy the previous cell and update it to extract technologies/skills from the resume\n",
    "2. Compare extracted technologies against the required technologies in the job requirements\n",
    "3. Provide a score (0-100) with clear reasoning based on technology match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2: Copy the work experience extraction cell above and modify it for technology extraction\n",
    "# Hints:\n",
    "# - Extract technologies/skills mentioned in the resume\n",
    "# - Compare against required technologies from job_req\n",
    "# - Score based on match percentage (0-100)\n",
    "# - Use a similar structure: prompt, schema, loop, DataFrame\n",
    "\n",
    "# Your code here:\n",
    "# 1. Define technology_extraction_prompt\n",
    "# 2. Define technology_schema (should include: technologies_found, required_technologies, match_score, reasoning)\n",
    "# 3. Loop through resume_samples\n",
    "# 4. Create technology_scores DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODO 3: Combine and Compare\n",
    "\n",
    "**Goal**: Compare the scores from the monolithic approach versus your decomposed approach.\n",
    "\n",
    "**Your Task**:\n",
    "- Merge the year data (`work_experience_scores`) with the technology scores\n",
    "- Create a composite score based on the extracted features\n",
    "- Compare your composite score against the monolithic 0-100 scores\n",
    "- Analyze the differences: which approach is more consistent? Which provides better explanations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## TODO 4: Extensions\n",
    "\n",
    "**Goal**: Add more sophisticated feature extraction and scoring.\n",
    "\n",
    "**Ideas to explore**:\n",
    "1. **Education Requirements**\n",
    "   - Extract degree level and field\n",
    "   - Check if it meets \"Bachelor's in CS or equivalent\"\n",
    "   - Score based on education match\n",
    "\n",
    "2. **Leadership/Mentoring**\n",
    "   - Look for evidence of mentoring junior developers\n",
    "   - Check for team lead or senior roles\n",
    "   - Score based on leadership experience\n",
    "\n",
    "3. **Multi-Resume Comparison**\n",
    "   - Run your improved scorer on 20 resumes\n",
    "   - Rank candidates by composite score\n",
    "   - Compare token costs: baseline vs. decomposed approach\n",
    "\n",
    "Pick one or more to implement!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
